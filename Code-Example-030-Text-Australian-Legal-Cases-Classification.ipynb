{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60a1db82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import bz2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f860156",
   "metadata": {},
   "source": [
    "# Dataset of Australian Legal Court Cases and General Wikipedia Pages\n",
    "You should download and look at the Court-Wiki-Dataset.txt\n",
    "\n",
    "file before you begin. You’ll see that the contents are sort of a pseudo-XML, where each text document begins with a \n",
    " tag, and ends with \n",
    ".\n",
    "\n",
    "Note that all of the Australia legal cases begin with something like \n",
    " that is, the doc id for an Australian legal case always starts with AU. You will be trying to figure out if the document is an Australian legal case by looking only at the contents of the document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1cef1f",
   "metadata": {},
   "source": [
    "# Step-1: Read the data source. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef04e379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line number:  100\n",
      "Line number:  200\n",
      "Line number:  300\n",
      "Line number:  400\n",
      "Line number:  500\n",
      "Line number:  600\n",
      "Line number:  700\n",
      "Line number:  800\n",
      "Line number:  800\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>purported appeal from orders made by federal m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bankruptcy noticefailure by creditor to attach...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>where documents produced to commission of inqu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>leave to appealinterlocutory judgmentwhether s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>applicant, a married person who had undergone ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>Le LanderonLe Landeron is a municipality in th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>Saint-Blaise, SwitzerlandSaint-Blaise is a mun...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>Tahirih Justice CenterThe Tahirih Justice Cent...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>The Ladies of Grace Adieu and Other StoriesThe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>Bring It On (Alistair Griffin song)\"Bring It O...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label\n",
       "0    purported appeal from orders made by federal m...      0\n",
       "1    bankruptcy noticefailure by creditor to attach...      0\n",
       "2    where documents produced to commission of inqu...      0\n",
       "3    leave to appealinterlocutory judgmentwhether s...      0\n",
       "4    applicant, a married person who had undergone ...      0\n",
       "..                                                 ...    ...\n",
       "795  Le LanderonLe Landeron is a municipality in th...      1\n",
       "796  Saint-Blaise, SwitzerlandSaint-Blaise is a mun...      1\n",
       "797  Tahirih Justice CenterThe Tahirih Justice Cent...      1\n",
       "798  The Ladies of Grace Adieu and Other StoriesThe...      1\n",
       "799  Bring It On (Alistair Griffin song)\"Bring It O...      1\n",
       "\n",
       "[800 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the file from here \n",
    "# https://github.com/kiat/Elements-of-Data-Analytics/blob/main/datasets/Court-Wiki-Dataset.txt.bz2\n",
    "\n",
    "file = bz2.open(\"./datasets/Court-Wiki-Dataset.txt.bz2\", \"r\")\n",
    "\n",
    "mlist = []\n",
    "\n",
    "\n",
    "count = 0 \n",
    "for line in file:\n",
    "    count +=1\n",
    "\n",
    "    line = (lambda x : (x[x.index('id=\"') + 4 : x.index('\" url=')], x[x.index('\">') + 2:][:-6]))(str(line))\n",
    "    mlist.append({'text' : line[1], 'label' : (lambda x: 0 if 'AU' in x else 1 )(line[0])})\n",
    "\n",
    "    if(count%100==0):\n",
    "        print(\"Line number: \" , count)\n",
    "\n",
    "\n",
    "# text_list\n",
    "print(\"Line number: \" , count)\n",
    "\n",
    "data = pd.DataFrame.from_dict(mlist)\n",
    "\n",
    "data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae0b40df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([377, 423])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = data['label']\n",
    "\n",
    "unique_labels, category_sizes = np.unique(labels, return_counts=True)\n",
    "category_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be405d5",
   "metadata": {},
   "source": [
    "# Step-2: Vectorize the text dataset using Tfidf Vectorizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c577d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples: 800, n_features: 510\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_df = 0.8,\n",
    "    min_df = 0.20,\n",
    "    stop_words=\"english\",\n",
    ")\n",
    "\n",
    "X_tfidf = vectorizer.fit_transform(list(data['text']))\n",
    "\n",
    "print(f\"n_samples: {X_tfidf.shape[0]}, n_features: {X_tfidf.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ea1e6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see what is inside it\n",
    "# X_tfidf.toarray()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472a9d7c-d12c-46de-9598-36384c0b5575",
   "metadata": {},
   "source": [
    "# Step 3: Classification using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b9a89d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Test/Train\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, labels, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f20eded0-a82e-4900-88f8-74e683264200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = LogisticRegression( fit_intercept=True)\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8168eb4-07ea-42f9-a018-811716b7ac0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99        79\n",
      "           1       0.99      0.99      0.99        81\n",
      "\n",
      "    accuracy                           0.99       160\n",
      "   macro avg       0.99      0.99      0.99       160\n",
      "weighted avg       0.99      0.99      0.99       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2116a58-aec4-423b-bc08-85fbada6611c",
   "metadata": {},
   "source": [
    "# Step 4: Random Feature Selection\n",
    "We can drop lots of features and we will see no drop in classification accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f137e21-90ca-4772-bdc6-9242a16b3a85",
   "metadata": {},
   "source": [
    "# Dropping 10% of Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab481bb8-eeb3-42c7-b5f2-40022a87e292",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns(arr, drop_rate):\n",
    "    num_columns = arr.shape[1]\n",
    "    num_drop = int(num_columns * drop_rate)  # Calculate 10% of the total columns\n",
    "    \n",
    "    # Generate a list of column indices to drop\n",
    "    drop_idx = np.random.choice(num_columns, num_drop, replace=False)\n",
    "    \n",
    "    # Remove the selected columns\n",
    "    new_arr = np.delete(arr, drop_idx, axis=1)\n",
    "    \n",
    "    return new_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9eaeb401-1e76-44f4-8596-8bb35bc61eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9875\n"
     ]
    }
   ],
   "source": [
    "# Drop 10% of Data Features and repeate the Classification Steps \n",
    "X_new = drop_columns(X_tfidf.toarray(), 0.10)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, labels, test_size=0.2, random_state=123)\n",
    "\n",
    "# A New Model with 10% less features\n",
    "model = LogisticRegression( fit_intercept=True)\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "# No Change in ACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96868f6d-ebc9-424e-ae2b-21229f6cc1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98125\n"
     ]
    }
   ],
   "source": [
    "# Drop 20% of Data Features \n",
    "X_new = drop_columns(X_tfidf.toarray(), 0.20)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, labels, test_size=0.2, random_state=123)\n",
    "\n",
    "# A New Model with 10% less features\n",
    "model = LogisticRegression( fit_intercept=True)\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "# No Change in ACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cc9f5b5-23fe-44b8-8d0e-8cac7caee277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98125\n"
     ]
    }
   ],
   "source": [
    "# Drop 30% of Data Features \n",
    "X_new = drop_columns(X_tfidf.toarray(), 0.30)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, labels, test_size=0.2, random_state=123)\n",
    "\n",
    "# A New Model with 10% less features\n",
    "model = LogisticRegression( fit_intercept=True)\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "# No Change in ACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ff1bfad-d547-4294-8a6f-14f1676ea202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 510)\n",
      "(800, 102)\n",
      "0.96875\n"
     ]
    }
   ],
   "source": [
    "# Drop 80% of Data Features \n",
    "X_new = drop_columns(X_tfidf.toarray(), 0.80)\n",
    "print(X_tfidf.shape)\n",
    "print(X_new.shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, labels, test_size=0.2, random_state=123)\n",
    "\n",
    "# A New Model with 10% less features\n",
    "model = LogisticRegression( fit_intercept=True)\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "# No Change in ACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af97f0ff-1011-4399-847c-973f7dd52c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 510)\n",
      "(800, 41)\n",
      "0.96875\n"
     ]
    }
   ],
   "source": [
    "# Drop 92% of Data Features \n",
    "X_new = drop_columns(X_tfidf.toarray(), 0.92)\n",
    "print(X_tfidf.shape)\n",
    "print(X_new.shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, labels, test_size=0.2, random_state=123)\n",
    "\n",
    "# A New Model with 10% less features\n",
    "model = LogisticRegression( fit_intercept=True)\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "# No Change in ACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cc3881-5107-43d3-bfb7-7a2b75b5f228",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
